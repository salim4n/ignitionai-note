---
title: D√©couverte du framework TFJS
description: D√©couverte du framework TFJS
---

Dans cet article, nous allons explorer comment cr√©er votre propre syst√®me de s√©curit√© qui utilise TensorFlow.js pour d√©tecter la pr√©sence d'une personne dans les cam√©ras de votre ordinateur. Cette d√©monstration montre comment l'intelligence artificielle peut √™tre int√©gr√©e dans des applications web pour cr√©er des fonctionnalit√©s innovantes et interactives

Cette article est redig√© dans le but de vous faire une premi√®re d√©couverte et donc de s'abstraire des difficult√©es, mais ne vous en faites pas, le prochain article est consacr√© √† la manipulation des tenseurs

En h√©bergement, j'utilise azure et vercel, libre √† vous d'adapter le code pour utiliser vos h√©bergeurs favoris

Verisure ne passera plus jamais chez vous apr√®s cette article. üòâ

### Qu'est-ce que TensorFlow.js ?

TensorFlow.js est une biblioth√®que open-source qui permet d'ex√©cuter des mod√®les de machine learning directement dans le navigateur ou sur Node.js.

Elle offre la possibilit√© de d√©ployer des mod√®les entra√Æn√©s avec TensorFlow sur des applications web, facilitant ainsi l'int√©gration de l'IA dans les applications front-end.

### Pourquoi utiliser TensorFlow.js ?

- **Simplicit√©**¬†: Int√©gration facile dans les applications web.
- **Performance**¬†: Ex√©cution rapide des mod√®les de machine learning gr√¢ce √† l'utilisation de WebGL et WebAssembly.
- **Flexibilit√©**¬†: Possibilit√© de d√©ployer des mod√®les pr√©-entra√Æn√©s ou d'entra√Æner des mod√®les directement dans le navigateur.

## Ok et maintenant commen√ßons

Avant toute chose il vous faut node.js, un √©diteur de code et git.

Ensuite vous pouvez cloner ce projet github.
[![pretorian-system](https://img.shields.io/badge/pretorian_system-%230077B5.svg?logo=github&logoColor=white)](https://github.com/salim4n/pretorian-system)

```bash
git clone https://github.com/salim4n/pretorian-system.git
```

Vous pouvez tester l'app ici :
[![pretorian-system](https://img.shields.io/badge/pretorian_system-8A2BE2)](https://web-pretorian-system.azurewebsites.net/)

C'est une impl√©mentation extr√™mement simple d'un mod√®le de detection d'objet, l'objectif ? Envoyer une notification telegram √† chaque detections de personne. Dans ce projet on utilise azure pour la persistance des donn√©es. Azure table pour l'utilisateur et azure blob pour le stockage des detections. Vous pouvez utiliser ce code et heberger √† votre guise, de mon c√¥t√© je paye¬†**z√©ro euro**¬†pour ce projet sur azure.

**C‚Äôest une application next.js avec typescript et tailwind-css.**

**Voici l‚Äôarchitecture du projet :**
![alt](./src/assets/arch_pretorian.webp)
**Il y'a beaucoup de code mais concentrons nous sur l'impl√©mentation de tensorflow.js et donc du composant** `Board.tsx`

**Imports et D√©pendances**

- Le code commence par importer les biblioth√®ques et les composants n√©cessaires, notamment¬†`TensorFlow.js`,¬†`coco-ssd`¬†pour la d√©tection d'objets,¬†`react-webcam`¬†pour acc√©der √† la webcam, et divers composants d'interface utilisateur.

```tsx
"use client"
import "@tensorflow/tfjs-backend-cpu"
import "@tensorflow/tfjs-backend-webgl"
import { useRef, useEffect, useState } from "react"
import {
  load as cocoSSDLoad,
  type ObjectDetection,
} from "@tensorflow-models/coco-ssd"
import * as tf from "@tensorflow/tfjs"
import Webcam from "react-webcam"
import { Detected, sendPicture } from "@/app/lib/send-detection/action"
import { Switch } from "@/components/ui/switch"
import { Skeleton } from "@/components/ui/skeleton"
import { Badge } from "@/components/ui/badge"
import { Avatar, AvatarFallback, AvatarImage } from "@/components/ui/avatar"
import {
  Card,
  CardContent,
  CardHeader,
  CardTitle,
  CardDescription,
} from "./ui/card"
```

**Composant Board**

- Ce composant est le c≈ìur de l'application. Il g√®re la d√©tection d'objets, la capture d'images et l'affichage des cam√©ras disponibles.
- Le composant utilise plusieurs √©tats pour g√©rer les cam√©ras disponibles (`cameras`), l'√©tat de chaque cam√©ra (`cameraChecked`), le mod√®le de d√©tection d'objets (`net`), et l'√©tat de chargement du mod√®le (`modelLoading`).
- Il utilise √©galement une r√©f√©rence¬†`webcamRefs`¬†pour stocker les instances de¬†`Webcam`¬†pour chaque cam√©ra.

```tsx
export default function Board({ user}) {
  const [cameras, setCameras] = useState<MediaDeviceInfo[]>([])
  const webcamRefs = useRef<Webcam[]>([])
  const [net, setNet] = useState<ObjectDetection | null>(null)
  const [cameraChecked, setCameraChecked] = useState<boolean[]>([])
  const [modelLoading, setModelLoading] = useState(true)
```

**Chargement du Mod√®le de D√©tection**

- La fonction¬†`runCocoSsd()`¬†est appel√©e pour charger le mod√®le de d√©tection d'objets¬†`coco-ssd`¬†de TensorFlow.js.
- Une fois le mod√®le charg√©,¬†`setModelLoading(false)`¬†est appel√© pour indiquer que le chargement est termin√©.

```tsx
async function runCocoSsd() {
  const loadedNet = await cocoSSDLoad()
  setNet(loadedNet)
  setModelLoading(false)
}
```

**D√©tection d'Objets et Capture d'Images**

- La fonction¬†`runObjectDetection()`¬†est appel√©e r√©guli√®rement (toutes les 3 secondes) pour d√©tecter les objets dans l'image de chaque cam√©ra activ√©e.
- Lorsqu'une personne est d√©tect√©e, la fonction¬†`sendPicture()`¬†est appel√©e pour envoyer l'image captur√©e et les informations de d√©tection.

```tsx
async function runObjectDetection(net: ObjectDetection) {
  webcamRefs.current.forEach(async webcam => {
    if (webcam !== null && webcam.video?.readyState === 4) {
      const objectDetected = await net.detect(webcam.video, undefined, 0.5)
      objectDetected.forEach(async o => {
        if (o.class === "person") {
          const body = {
            detected: o,
            picture: webcam.getScreenshot({ width: 640, height: 480 }),
          }
          await sendPicture(body as Detected, user)
        }
      })
    }
  })
}
```

**Cycle de Vie et Nettoyage**

- Dans le¬†`useEffect()`¬†qui suit le chargement du mod√®le, un intervalle est d√©fini pour appeler r√©guli√®rement¬†`runObjectDetection()`.
- Lors du d√©montage du composant, l'intervalle est effac√©, et les ressources TensorFlow.js sont lib√©r√©es.

```tsx
useEffect(() => {
  if (net) {
    const detectInterval = setInterval(() => {
      runObjectDetection(net)
    }, 3000)

    return () => {
      clearInterval(detectInterval)
      net?.dispose()
      tf.disposeVariables()
    }
  }
}, [net])
```

**Gestion du Composant lors du chargement du mod√®le**

- Lorsque le mod√®le est en cours de chargement, un √©cran de chargement avec un avatar et un badge est affich√©.

```tsx
if (modelLoading) {
  return (
    <div className="grid grid-cols-1 gap-4 lg:grid-cols-2 lg:gap-8">
      <Card className="m-3 z-50">
        <CardContent className="m-5">
          <div className="w-full text-center flex justify-center items-center">
            <Avatar className="w-48 h-48">
              <AvatarImage src="/icon.jpeg" />
              <AvatarFallback>PR</AvatarFallback>
            </Avatar>
            <Badge variant="default" className="mt-4">
              <strong className="ml-4">
                {modelLoading && "Chargement du mod√®le de reconnaissance"}
              </strong>
            </Badge>
          </div>
        </CardContent>
      </Card>
      <Card className="m-3 w-full lg:col-span-2 flex-grow">
        <CardContent>
          <div className="grid grid-cols-1 gap-4 lg:grid-cols-2 lg:gap-8">
            {Array.from({ length: 4 }).map((_, index) => (
              <Card key={index}>
                <CardHeader>
                  <Skeleton className="w-full h-10" />
                </CardHeader>
                <CardContent>
                  <Skeleton className="w-full h-40" />
                </CardContent>
              </Card>
            ))}
          </div>
        </CardContent>
      </Card>
    </div>
  )
}
```

**Affichage du Composant**

- Lorsque le mod√®le est charg√©, le composant affiche une carte pour chaque cam√©ra disponible, avec un interrupteur pour activer/d√©sactiver la cam√©ra et l'affichage de la capture vid√©o.

```tsx
  return (
    <div className="grid grid-cols-1 gap-4 lg:grid-cols-2 lg:gap-8">
      {cameras.map((camera, index) => (
        <Card key={index} className="flex flex-col items-center mt-5">
          <CardHeader>
            <CardTitle>{camera.label}</CardTitle>
            <CardDescription>
              <div className="flex item-center">
              <Switch
                id={camera.deviceId}
                defaultChecked
                checked={cameraChecked[index]}
                onCheckedChange={(checked) => {
                  setCameraChecked((prev) => prev.map((_, i) => i === index ? checked : _))
                }}
                className="m-1 relative"
              />
               <strong>
                {
                  cameraChecked[index] ? 'On' : 'Off'
                }
               </strong>
              </div>
            </CardDescription>
          </CardHeader>
          <CardContent>
          {cameraChecked[index] && (
            <Webcam
              audio={false}
              videoConstraints={{
                deviceId: camera.deviceId,
              }}
              ref={(el) => {
                if (el) {
                  webcamRefs.current[index] = el
                }
              }}
              key={index}
              width={640}
              height={480}
              className='m-1 rounded-md border-gray-500 border-2'
            />
          )}
          </CardContent>
        </Card>
      ))}
    </div>
  )
}
```

Vous voyez, je vous avais pr√©venu que nous allions commenc√© tout doucement üòÑ.

Ici, nous avons utilis√© un node package manager mis √† disposition pour l'inf√©rence du mod√®le, nous n'avons pas √† g√©rer manuellement les d√©pendances complexes ou la configuration des environnements d'ex√©cution sp√©cifiques √† l'IA. Gr√¢ce √† l'utilisation de TensorFlow.js et des packages tels que¬†`@tensorflow-models/coco-ssd`, tout le processus d'int√©gration, de chargement et d'ex√©cution du mod√®le se fait de mani√®re automatis√©e et optimis√©e. Ces packages g√®rent les d√©tails sous-jacents tels que le chargement des poids du mod√®le, l'initialisation des tensors, et l'optimisation des calculs pour tirer parti des capacit√©s de traitement disponible, que ce soit sur CPU ou GPU via WebGL. Cela permet de concentrer les efforts sur le d√©veloppement des fonctionnalit√©s sp√©cifiques √† l'application, comme la logique de capture d'image et la r√©action aux r√©sultats de l'inf√©rence, plut√¥t que sur la gestion de l'infrastructure de machine learning.

Et voila c'est d√©j√¢ termin√©, encore une fois on reste simple pour cette premi√®re d√©couverte.

Mais je vous promet que le prochain article va √™tre tr√®s tr√®s int√©ressant.

Si jamais tout cela ne vous int√©resse pas mais que vous aimeriez bien utiliser des mod√®les¬†*Computer Vision*¬†dans vos projets ou m√™me¬†*NLP*, je vous invite fortement √† vous diriger du c√¥t√© de¬†**Mediapipe**¬†ou de¬†**Transformers.js**
