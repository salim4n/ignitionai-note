---
title: Construire une Vector Database From Scratch avec TensorFlow.js
description: Construire une Vector Database From Scratch avec TensorFlow.js
---

Une **Vector Database** est un concept fondamental pour de nombreuses applications d'intelligence artificielle, comme la recherche sÃ©mantique, les systÃ¨mes de recommandation ou encore l'analyse de similaritÃ©. Ce projet montre comment en construire une version simplifiÃ©e en utilisant **TensorFlow.js** pour l'encodage et la recherche de vecteurs.

---

## Pourquoi une Vector Database ?

Lorsqu'on traite des donnÃ©es textuelles ou multimÃ©dias, il est souvent nÃ©cessaire de reprÃ©senter ces donnÃ©es sous une forme que les ordinateurs peuvent manipuler efficacement : des **vecteurs**. Les vecteurs sont des reprÃ©sentations numÃ©riques qui capturent les relations sÃ©mantiques entre les Ã©lÃ©ments. Par exemple :

- Deux phrases similaires auront des vecteurs proches.
- Une image et une description correspondante peuvent partager des caractÃ©ristiques vectorielles similaires.

Dans une Vector Database, nous stockons ces vecteurs et offrons des moyens efficaces de rechercher ceux qui sont les plus proches d'un vecteur donnÃ© (par exemple, la reprÃ©sentation d'une requÃªte utilisateur).

---

## Architecture GÃ©nÃ©rale du Projet

1. **Encodage** : Transformer une phrase en vecteur Ã  l'aide d'un modÃ¨le prÃ©-entraÃ®nÃ© comme le **Universal Sentence Encoder**.
2. **Stockage** : Conserver ces vecteurs avec leurs identifiants dans une structure simple.
3. **Recherche** : Comparer un vecteur de requÃªte avec les vecteurs existants pour trouver les Ã©lÃ©ments les plus proches, en utilisant une mesure de similaritÃ© comme la distance cosinus.

---

### Ã‰tape 1 : Encodage des Phrases avec TensorFlow.js

Le cÅ“ur de notre Vector DB repose sur le **Universal Sentence Encoder (USE)**, un modÃ¨le capable de transformer des phrases en vecteurs numÃ©riques. Avec TensorFlow.js, ce modÃ¨le peut Ãªtre chargÃ© directement dans le navigateur.

#### Chargement du ModÃ¨le

Voici comment charger le modÃ¨le USE dans TensorFlow.js :

```typescript
import * as tf from '@tensorflow/tfjs';
import * as use from '@tensorflow-models/universal-sentence-encoder';

export class VectorDb {
  private model: use.UniversalSentenceEncoder | null = null;

  // Charger le modÃ¨le au dÃ©marrage
  async loadModel() {
    this.model = await use.load();
    console.log('ModÃ¨le chargÃ© avec succÃ¨sÂ !');
  }
}
```

**Explication** :  

- `use.load()` charge le modÃ¨le dans le navigateur.
- Ce modÃ¨le peut encoder une phrase ou un texte en un vecteur Ã  512 dimensions.

---

#### Encodage d'une Phrase

Une fois le modÃ¨le chargÃ©, nous pouvons encoder une phrase. Chaque phrase est transformÃ©e en un vecteur dense.

```typescript
async addSentence(id: string, sentence: string) {
  if (!this.model) throw new Error('ModÃ¨le non chargÃ©');
  
  // Encodage de la phrase
  const embeddings = await this.model.embed([sentence]);
  console.log(`Vecteur pour "${sentence}" :`, embeddings.arraySync());
}
```

**Explication** :  

- `embed` transforme un tableau de phrases en vecteurs.
- Chaque vecteur est un tableau de 512 nombres reprÃ©sentant la phrase.

---

### Ã‰tape 2 : Stockage des Vecteurs

Une fois encodÃ©s, les vecteurs doivent Ãªtre stockÃ©s pour pouvoir Ãªtre comparÃ©s lors de futures recherches. Une structure simple comme un tableau peut suffire pour notre dÃ©monstration.

```typescript
private vectors: { id: string; vector: tf.Tensor }[] = [];

async addSentence(id: string, sentence: string) {
  if (!this.model) throw new Error('ModÃ¨le non chargÃ©');
  
  const embeddings = await this.model.embed([sentence]);
  this.vectors.push({ id, vector: embeddings });
  console.log(`Phrase ajoutÃ©e avec l'ID : ${id}`);
}
```

**Explication** :  

- Chaque vecteur est stockÃ© avec un identifiant (`id`) pour pouvoir retrouver l'Ã©lÃ©ment original.
- Dans une implÃ©mentation avancÃ©e, on utiliserait une base de donnÃ©es optimisÃ©e pour les recherches vectorielles, comme **Faiss** ou **Pinecone**.

---

### Ã‰tape 3 : Recherche Vectorielle

Pour rechercher les vecteurs les plus proches, nous utilisons une mesure de similaritÃ© appelÃ©e **cosine similarity** (distance cosinus). Plus deux vecteurs pointent dans la mÃªme direction, plus leur similaritÃ© est grande.

#### Calcul de la SimilaritÃ© Cosinus

Voici une fonction qui calcule la similaritÃ© cosinus entre deux vecteurs :

```typescript
function cosineSimilarity(vectorA: tf.Tensor, vectorB: tf.Tensor): tf.Scalar {
  const dotProduct = tf.sum(tf.mul(vectorA, vectorB));
  const normA = tf.sqrt(tf.sum(tf.pow(vectorA, 2)));
  const normB = tf.sqrt(tf.sum(tf.pow(vectorB, 2)));
  return dotProduct.div(normA.mul(normB));
}
```

**Explication** :  

- Le produit scalaire (`dotProduct`) mesure l'alignement entre deux vecteurs.
- Les normes (`normA` et `normB`) normalisent les vecteurs pour obtenir une valeur entre -1 et 1.

---

#### Trouver les Meilleurs RÃ©sultats

Nous comparons le vecteur de requÃªte avec tous les vecteurs stockÃ©s et retournons les rÃ©sultats les plus similaires.

```typescript
search(query: string, topK: number = 5) {
  if (!this.model) throw new Error('ModÃ¨le non chargÃ©');
  
  const queryEmbedding = this.model.embed([query]);
  const scores = this.vectors.map(({ id, vector }) => ({
    id,
    score: cosineSimilarity(queryEmbedding, vector).dataSync()[0],
  }));
  
  return scores
    .sort((a, b) => b.score - a.score)
    .slice(0, topK);
}
```

**Explication** :  

- `map` calcule la similaritÃ© pour chaque vecteur.
- Les scores sont triÃ©s pour retourner les `topK` rÃ©sultats.

---

### Interface Utilisateur avec React

Pour rendre cette dÃ©monstration interactive, nous intÃ©grons le tout dans une modal avec React :

```tsx
import React from 'react';
import { VectorDb } from './VectorDb';

const VectorDbDemo: React.FC = () => {
  const [db, setDb] = React.useState<VectorDb | null>(null);

  React.useEffect(() => {
    const initDb = async () => {
      const vectorDb = new VectorDb();
      await vectorDb.loadModel();
      setDb(vectorDb);
    };
    initDb();
  }, []);

  return (
    <div>
      <h1>Vector DB Demo</h1>
      <p>Ajoutez des phrases et recherchez des correspondancesÂ !</p>
      {/* Formulaires pour ajouter des phrases et effectuer des recherches */}
    </div>
  );
};

export default VectorDbDemo;
```

---

### RÃ©sultat Final

Avec cette dÃ©monstration, vous pouvez :

1. **Ajouter des phrases** : Encodez et stockez des phrases dans la Vector DB.
2. **Rechercher des correspondances** : Trouvez les phrases les plus proches d'une requÃªte.
3. **Comprendre les bases des Vector DB** : Approfondissez vos connaissances sur l'encodage, la similaritÃ© cosinus et la gestion des vecteurs.

Essayez cette dÃ©mo directement sur mon site [IgnitionAI](https://www.ignitionai.fr). ðŸŽ‰
(cliquez juste sur l'icone de base de donnÃ©es, Ã§a va vous ouvrir la dÃ©mo)

---
